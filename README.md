# Proyecto Final - MLOps con CRISP-DM

## PredicciÃ³n de Abandono de Clientes (Churn Prediction)

Proyecto completo de Machine Learning Operations siguiendo la metodologÃ­a CRISP-DM para predecir el abandono de clientes en un call center.

## ğŸ“‹ Estructura del Proyecto

```
MLOPS-Final-Proyect/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ synthetic/
â”‚       â””â”€â”€ synthetic_calls.csv          # Dataset sintÃ©tico
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ EDA_AnÃ¡lisis_Exploratorio.ipynb  # AnÃ¡lisis exploratorio
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ generate_synthetic.py        # GeneraciÃ³n de datos sintÃ©ticos
â”‚   â”‚   â”œâ”€â”€ data_preparation.py          # Pipeline de preparaciÃ³n de datos
â”‚   â”‚   â””â”€â”€ pipeline.py                  # Pipeline original (legacy)
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ model_training.py            # Entrenamiento con MLflow
â”‚   â”‚   â””â”€â”€ model_evaluation.py          # EvaluaciÃ³n completa
â”‚   â””â”€â”€ main.py                          # Script principal
â”œâ”€â”€ results/
â”‚   â””â”€â”€ evaluation/                      # Resultados de evaluaciÃ³n
â”œâ”€â”€ requirements.txt                     # Dependencias
â””â”€â”€ README.md                            # Este archivo
```

## ğŸš€ InstalaciÃ³n

### 1. Crear entorno virtual (recomendado)

```bash
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate
```

### 2. Instalar dependencias

```bash
pip install -r requirements.txt
```

### 3. Generar datos sintÃ©ticos (si no existen)

```bash
python src/data/generate_synthetic.py
```

## ğŸ“Š Uso

### OpciÃ³n 1: Ejecutar pipeline completo

```bash
python src/main.py
```

Este script ejecuta:
1. PreparaciÃ³n de datos
2. Entrenamiento de 4 modelos con MLflow
3. EvaluaciÃ³n completa del mejor modelo

### OpciÃ³n 2: Ejecutar componentes individuales

#### Preparar datos
```python
from src.data.data_preparation import prepare_data
data_dict = prepare_data()
```

#### Entrenar modelos
```python
from src.models.model_training import train_all_models
results = train_all_models(data_dict)
```

#### Evaluar modelo
```python
from src.models.model_evaluation import load_best_model, evaluate_on_all_splits
model, _ = load_best_model()
results = evaluate_on_all_splits(model, data_dict)
```

## ğŸ”§ ConfiguraciÃ³n de MLflow

### 1. Iniciar servidor MLflow

En una terminal separada:

```bash
mlflow ui --backend-store-uri sqlite:///mlflow.db --default-artifact-root ./mlruns
```

O si prefieres usar el servidor en localhost:5000:

```bash
mlflow server --backend-store-uri sqlite:///mlflow.db --default-artifact-root ./mlruns --host 0.0.0.0 --port 5000
```

### 2. Acceder a la UI

Abre tu navegador en: `http://localhost:5000`

## ğŸ“ˆ Modelos Implementados

1. **Logistic Regression** - Modelo lineal bÃ¡sico
2. **Random Forest** - Ensemble de Ã¡rboles de decisiÃ³n
3. **XGBoost** - Gradient boosting optimizado
4. **LightGBM** - Gradient boosting rÃ¡pido y eficiente

Todos los modelos incluyen:
- Hyperparameter tuning con RandomizedSearchCV
- Logging completo en MLflow
- ComparaciÃ³n sistemÃ¡tica
- Registro en Model Registry

## ğŸ“Š MÃ©tricas de EvaluaciÃ³n

- **Accuracy** - PrecisiÃ³n general
- **Precision** - PrecisiÃ³n de predicciones positivas
- **Recall** - Sensibilidad
- **F1-Score** - Media armÃ³nica de precision y recall
- **ROC-AUC** - Ãrea bajo la curva ROC
- **Log Loss** - PÃ©rdida logarÃ­tmica

## ğŸ“ Resultados

Los resultados de la evaluaciÃ³n se guardan en `results/evaluation/`:
- Matriz de confusiÃ³n
- Curvas ROC
- Curvas Precision-Recall
- Feature importance

## ğŸ” AnÃ¡lisis Exploratorio

Ejecuta el notebook Jupyter para ver el anÃ¡lisis completo:

```bash
jupyter notebook notebooks/EDA_AnÃ¡lisis_Exploratorio.ipynb
```

## ğŸ“ Requisitos del Proyecto (CRISP-DM)

### âœ… Fase 1: ComprensiÃ³n del Negocio (20 puntos)
- [ ] DocumentaciÃ³n del problema de negocio

### âœ… Fase 2: ComprensiÃ³n de los Datos (10 puntos)
- [x] Dataset sintÃ©tico con 30,000 registros
- [x] AnÃ¡lisis exploratorio completo (EDA)

### âœ… Fase 3: PreparaciÃ³n de Datos (20 puntos)
- [x] Pipeline de limpieza
- [x] Feature engineering
- [x] Transformaciones
- [x] DivisiÃ³n temporal train/val/test

### âœ… Fase 4: Modelado con MLflow (20 puntos)
- [x] ConfiguraciÃ³n de MLflow
- [x] 4 algoritmos diferentes
- [x] Hyperparameter tuning
- [x] Logging de parÃ¡metros y mÃ©tricas
- [x] Model Registry

### âœ… Fase 5: EvaluaciÃ³n (10 puntos)
- [x] MÃ©tricas completas
- [x] Matriz de confusiÃ³n
- [x] Curvas ROC y Precision-Recall
- [x] Feature importance

### â³ Fase 6: PresentaciÃ³n (20 puntos)
- [ ] PresentaciÃ³n ejecutiva (mÃ¡ximo 20 slides)

## ğŸ› ï¸ TecnologÃ­as Utilizadas

- **Python 3.11+**
- **Pandas** - ManipulaciÃ³n de datos
- **Scikit-learn** - Machine Learning
- **XGBoost** - Gradient Boosting
- **LightGBM** - Gradient Boosting rÃ¡pido
- **MLflow** - Experiment tracking y Model Registry
- **Matplotlib/Seaborn** - VisualizaciÃ³n

## ğŸ“ Contacto

Para preguntas o problemas, consulta la documentaciÃ³n del proyecto o contacta al equipo.

## ğŸ“„ Licencia

Este proyecto es parte del curso de Machine Learning Operations.
